# === FILE: README.md ===
# FlowBot - AI Workflow Assistant ğŸ¤–

A local-first AI assistant that records, analyzes, and automates your workflows.
Built for the Hackathon: "The AGI Assistant" - implements Observe â†’ Understand â†’ Act pipeline.

## ğŸ¯ Features

- **ğŸ™ï¸ Workflow Recording**: Captures keyboard, mouse, screen, and audio
- **ğŸ” AI Analysis**: Uses Ollama LLM to understand your workflows
- **ğŸ§¹ Smart Cleaning**: Removes noise and formats for LLM consumption
- **ğŸ“Š Workflow Visualization**: Modern PyQt6 GUI to view and manage recordings
- **ğŸ¤ Audio Transcription**: Offline transcription with Vosk or online with Whisper
- **âš¡ Automation (Coming Soon)**: Execute workflows automatically
- **ğŸ—‘ï¸ File Management**: Delete sessions and clean up storage

## ğŸ“ Project Structure

```
â”œâ”€â”€ gui.py                      # ğŸ¨ Modern PyQt6 GUI interface
â”œâ”€â”€ main.py                     # ğŸ¯ CLI orchestrator
â”œâ”€â”€ recorder.py                 # ğŸ“¹ Screen/audio/input recorder
â”œâ”€â”€ analyzer.py                 # ğŸ” Workflow analyzer with OCR
â”œâ”€â”€ clean_workflow.py           # ğŸ§¹ Workflow cleaner
â”œâ”€â”€ ollama_workflow_analyzer.py # ğŸ¤– AI analysis with Ollama
â”œâ”€â”€ automator.py                # âš¡ Workflow automation
â”œâ”€â”€ launch_gui.bat/sh           # ğŸš€ GUI launchers
â”œâ”€â”€ requirements_gui.txt        # ğŸ“¦ GUI dependencies
â””â”€â”€ README.md                   # ğŸ“– This file
```

IMPORTANT: This is an MVP/proof-of-concept. Test only on your own machine. ALWAYS run dry-run first.

---

## ğŸš€ Quick Start

### Option 1: Modern GUI (Recommended)

1. **Install Dependencies**
```bash
pip install -r requirements_gui.txt
```

2. **Install Ollama** (for AI analysis)
- Download from: https://ollama.ai
- Install the model: `ollama pull mistral:latest`

3. **Launch the GUI**
```bash
# Windows
launch_gui.bat

# Linux/macOS
chmod +x launch_gui.sh
./launch_gui.sh

# Or directly
python gui.py
```

### Option 2: Command Line Interface

1. **Setup Environment**
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
pip install -r requirements_gui.txt
```

2. **Install System Dependencies**
- **Tesseract OCR**: Required for text recognition
  - macOS: `brew install tesseract`
  - Ubuntu: `sudo apt install tesseract-ocr`
  - Windows: Download from [GitHub](https://github.com/tesseract-ocr/tesseract)

- **Ollama**: Required for AI analysis
  - Download from: https://ollama.ai
  - Run: `ollama pull mistral:latest`

3. **Record and Analyze**
```bash
# Single recording session with auto-analysis
python main.py --mode once

# Continuous recording mode
python main.py --mode continuous
```

---

## ğŸ¨ GUI Features

### Main Interface

The FlowBot GUI provides a modern, dark-themed interface with:

**Left Panel - Control Center**
- ğŸ™ï¸ Recording controls (Start/Stop)
- âš™ï¸ Configuration options (Vosk/Whisper, auto-analysis)
- ğŸ“‹ Session browser with status icons
- ğŸ—‘ï¸ Delete sessions

**Right Panel - Tabbed Views**

1. **ğŸ“‹ Workflow Tab**
   - View raw and cleaned workflows
   - Analyze, clean, and run Ollama analysis
   - See detailed action steps

2. **ğŸ¤– AI Analysis Tab**
   - View Ollama-generated insights
   - See automation suggestions
   - Understand workflow intent

3. **ğŸ¤ Transcripts Tab**
   - Browse audio transcriptions
   - See what was said during recording
   - Correlate speech with actions

4. **âš¡ Automation Tab** (Coming Soon)
   - Extract automation steps
   - Execute automated workflows
   - Monitor execution progress

### Session Status Icons

- ğŸ“ = Events recorded
- ğŸ“Š = Workflow analyzed
- ğŸ§¹ = Workflow cleaned
- ğŸ¤– = AI analysis complete

---

## ğŸ“– Usage Guide

### Recording a Workflow

1. Click **"âºï¸ Start Recording"**
2. Perform your workflow (typing, clicking, etc.)
3. Speak to describe what you're doing (optional)
4. Click **"â¹ï¸ Stop Recording"**
5. Wait for auto-analysis to complete (if enabled)

### Viewing Results

1. Select a session from the list
2. Navigate through tabs to see:
   - Raw workflow data
   - Cleaned workflow
   - AI insights
   - Audio transcripts

### AI Analysis

The AI analysis provides:
- **Summary**: What you did in plain English
- **Transcript Insight**: What your voice revealed about intent
- **Automation**: Suggestions for automating repetitive tasks
- **Steps**: Detailed automation steps

### Managing Sessions

- **Refresh**: Update session list
- **Delete**: Remove session and all related files
  - Deletes: recordings, workflows, analyses, transcripts

---

## ğŸ› ï¸ Configuration

### Transcription Options

- **Vosk (Offline)**: Fast, local transcription. Good for privacy.
- **Whisper (Online)**: Higher quality, requires internet.

### Auto-Analysis

Enable to automatically:
1. Analyze workflow after recording
2. Clean workflow JSON
3. Run Ollama AI analysis

---

## ğŸ”§ Command Line Tools

All features are also available via command line:

```bash
# Record a workflow
python recorder.py

# Analyze a recording
python analyzer.py recordings/20251028_075237

# Clean a workflow
python clean_workflow.py workflows/workflow_20251028_075237.json

# Run AI analysis
python ollama_workflow_analyzer.py clean_workflows/cleaned_20251028_075237.json

# Full pipeline (one session)
python main.py --mode once --vosk
```

---

## ğŸ”’ Safety & Privacy

- âœ… **100% Local**: Everything runs on your machine
- âœ… **No Cloud**: No data sent to external servers (except Ollama if configured for remote)
- âœ… **Offline First**: Works without internet (use Vosk for transcription)
- âš ï¸ **Review Before Automation**: Always dry-run workflows before execution
- ğŸ—‘ï¸ **Easy Cleanup**: Delete recordings containing sensitive data

## ğŸ› Troubleshooting

### Ollama Connection Error
```bash
# Make sure Ollama is running
ollama serve

# Check if model is installed
ollama list

# Install the model
ollama pull mistral:latest
```

### Timeout Errors
- Increase timeout in `ollama_workflow_analyzer.py` (currently 300s)
- Use a smaller/faster model: `ollama pull mistral:latest`

### Recording Issues
- Ensure you have microphone permissions
- Check Tesseract is installed: `tesseract --version`
- Install missing Python packages: `pip install -r requirements_gui.txt`

### GUI Won't Start
```bash
# Install PyQt6
pip install PyQt6

# Check Python version (need 3.8+)
python --version

# Try running directly
python gui.py
```

---

## ğŸ“¦ Dependencies

### Core Requirements
- Python 3.8+
- PyQt6 (GUI framework)
- pynput (keyboard/mouse capture)
- Pillow (screenshots)
- pytesseract (OCR)
- vosk (offline transcription)
- requests (Ollama communication)

### System Requirements
- Tesseract OCR binary
- Ollama (for AI analysis)

---

## ğŸš§ Roadmap

- [x] Workflow recording
- [x] Audio transcription
- [x] OCR and action analysis
- [x] Workflow cleaning
- [x] AI analysis with Ollama
- [x] Modern PyQt6 GUI
- [x] Session management
- [ ] Workflow automation execution
- [ ] Custom automation scripts
- [ ] Workflow templates
- [ ] Cloud sync (optional)
- [ ] Mobile companion app

---

## ğŸ“„ License

This is a hackathon MVP/proof-of-concept. Test only on your own machine.

---

## ğŸ¤ Contributing

This project is part of "The AGI Assistant" hackathon. Contributions welcome!

---

**Built with â¤ï¸ for local-first AI assistance**

# Minimal Python packages (CPU-friendly)

opencv-python
pillow
numpy
pytesseract
pyautogui
pynput
sounddevice
scipy
PySimpleGUI
python-dotenv

# Optional (for better STT)
# whisper or faster-whisper (CPU/GPU)
